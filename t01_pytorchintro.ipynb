{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AnpH_sWCa60Z",
        "vdAtPWYwVyE5",
        "6h2S5DY6WAwf",
        "5qXtesdINPWY",
        "gXKG-s1aNPWX",
        "jyRyK_TDNPWZ",
        "5BYUx8vANPWb",
        "rVSKnQBVNPWb",
        "V1EZlo5tNPWh",
        "66D54POiNPWi",
        "OXJF5dkONPWi",
        "lqG6fnN_NPWl",
        "y6bljUYONPWm",
        "U7Fd-Z0NNPWp",
        "Z1RDOWcBNPWs",
        "TNNBh0WyNPWt",
        "w_vaSHSNNPWv",
        "Vthkm2pwNPWw",
        "LRAoLyHcNPWy",
        "Bls8DFvKNPW1",
        "y380mfhLNPXg"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedyusef9/deep_learning_course/blob/t01_PyTorchIntro/t01_pytorchintro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqeL3xpUNPWE"
      },
      "source": [
        "$$\n",
        "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
        "$$\n",
        "\n",
        "# Deep Learning - Tutorial 1: Introduction to PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jURS-Vi_NPWH"
      },
      "source": [
        "In this tutorial, we will cover:\n",
        "* Course info\n",
        "* Environment setup with `conda`\n",
        "* Jupyter/Colab: Using notebooks\n",
        "* Pytorch:\n",
        "  - Tensors basics: indexing, datatypes, math\n",
        "  - Broadcasting\n",
        "  - Intro to automatic differentiation\n",
        "\n",
        "Also in this tutorial, but for self-study:\n",
        "* Basic Python: Basic data types (Containers, Lists, Dictionaries, Sets, Tuples), Functions, Classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "IPPKHrE3NPWI"
      },
      "source": [
        "## Administration and General Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtrPVjUhNPWK"
      },
      "source": [
        "My info:\n",
        "- Nareed H. Farhat\n",
        "- nhashe01@campus.haifa.ac.il\n",
        "- Office hour: Monday, 15:00-16:00, or zoom, scheduled via email.\n",
        "\n",
        "\n",
        "Course:\n",
        "- Course website is on moodle.\n",
        "- Updates will be posted there (but emails will be sent aswell)\n",
        "- Post questions regarding assignments and project on **Moodle** only! (Not email)\n",
        "- For personal administrative requests/delays: email Rotem.\n",
        "- For appeals/questions about grades: Email Rotem/Nareed.\n",
        "\n",
        "Lectures\n",
        "- Provide a high level presentation of most core topics of Deep Learning, including very recent topics.\n",
        "- Give mathematical background and justifications.\n",
        "- Supplementary material with more in-depth examples or advanced topics.\n",
        "\n",
        "Tutorials:\n",
        "- Structure is usually a short theory reminders part and then step-by-step technical implementation of a real  problem.\n",
        "- Technical, meant to help you understand the implementation details behind deep learning.\n",
        "- **Highly relevant** for success in the homework assignments.\n",
        "<!-- - After this tutorial you should clone the [tutorials repo](https://github.com/vistalab-technion/cs236781-tutorials), install the conda env and play with the code. -->\n",
        "\n",
        "Homework:\n",
        "- Two HW assignments, quite heavy load. Best to tackle them after you have sufficient programming experience.\n",
        "- Almost entirely \"wet\" i.e. implementation of real algorithms with real data.\n",
        "- Should be done in pairs.\n",
        "<!-- - Some will require use of GPUs. We will provide access to course servers - **please register**. -->\n",
        "<!-- - Read the [getting started page](https://vistalab-technion.github.io/cs236781/assignments/getting-started) and [collaboration policy](https://vistalab-technion.github.io/cs236781/info/#administration) carefully! -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDCboc7BNPWP"
      },
      "source": [
        "## Environment setup\n",
        "\n",
        "Two setup options are available\n",
        "1. For setting up a local enviroment on your copmuter.\n",
        "2. For working on Colab.\n",
        "\n",
        "Run one of the given two setups based on chosen usage, in the toturials we'll work with (2) Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Local installation and setup"
      ],
      "metadata": {
        "id": "AnpH_sWCa60Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUyzsrpUNPWR"
      },
      "source": [
        "To install and manage all the necessary packages and dependencies for the\n",
        "course tutorials and assignments, we use [conda](https://conda.io), a popular package-manager for python.\n",
        "\n",
        "- The tutorial notebooks come with an `environment.yml` file which defines which third-party libraries we depend on.\n",
        "- Conda will use this file to create a virtual environment for you.\n",
        "- This virtual environment includes python and all other packages and tools we specified, separated from any preexisting python installation you may have."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installation"
      ],
      "metadata": {
        "id": "vdAtPWYwVyE5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmucdgvwNPWR"
      },
      "source": [
        "\n",
        "\n",
        "1. Install the python3 version of [miniconda](https://conda.io/miniconda.html).\n",
        "Follow the [installation instructions](https://conda.io/docs/user-guide/install/index.html)\n",
        "for your platform.\n",
        "\n",
        "2. Install all dependencies (into a virtual env) with `conda`:\n",
        "\n",
        "    ```shell\n",
        "    conda env update -f environment.yml\n",
        "    ```\n",
        "    \n",
        "    This will also create a new virtual env (`dl317024-tutorials`) if it doesn't already exist.\n",
        "\n",
        "3. To activate the virtual environment (set up `$PATH`):\n",
        "\n",
        "    ```shell\n",
        "    conda activate dl317024-tutorials\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3CPFl2KNPWS"
      },
      "source": [
        "You can also check what conda environments you have and which is active, run\n",
        "\n",
        "```shell\n",
        "conda env list\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD8TzV8ENPWS"
      },
      "source": [
        "#### Short demo of environment setup\n",
        "\n",
        "A video demonstrating enviroment installation and wokring with `conda` locally will be uploaded to moodle."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running Jupyter"
      ],
      "metadata": {
        "id": "6h2S5DY6WAwf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLOeQnVINPWS"
      },
      "source": [
        "\n",
        "\n",
        "From a terminal, enter the folder contaning the tutorial notebooks.\n",
        "1. Make sure that the active conda environment is `dl317024-tutorials`:\n",
        "\n",
        "    ```shell\n",
        "    conda activate dl317024-tutorials\n",
        "    ```\n",
        "\n",
        "2. Run jupyter with\n",
        "\n",
        "    ```shell\n",
        "    jupyter lab\n",
        "    ```\n",
        "    \n",
        "    This will start a [jupyter lab](https://jupyterlab.readthedocs.io/en/stable/)\n",
        "    server and open your browser at the local server's url. You can now start working with the notebooks.\n",
        "\n",
        "If you're new to jupyter notebooks, you can get started by reading the\n",
        "[UI guide](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "and also about how to use notebooks in\n",
        "[JupyterLab](https://jupyterlab.readthedocs.io/en/latest/user/notebook.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Using *Google Colab*"
      ],
      "metadata": {
        "id": "_P5mZD2Ob2jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab, short for Colaboratory, is an incredible platform that provides free access to GPU (Graphics Processing Unit) and TPU (Tensor Processing Unit) resources, making it an ideal environment for running deep learning experiments without the need for specialized hardware.\n",
        "\n",
        "#### Key Features:\n",
        "\n",
        "1. **Free GPU/TPU Resources:**\n",
        "Colab allows you to leverage powerful GPUs and TPUs at no cost. This is a game-changer for training complex deep learning models, significantly speeding up computation times.\n",
        "\n",
        "2. **Jupyter Notebook Integration:**\n",
        "Colab is based on the Jupyter Notebook, allowing you to create interactive and shareable documents that combine code, text, and visualizations.\n",
        "\n",
        "3. **Easy Collaboration:**\n",
        "You can share your Colab notebooks just like you would with Google Docs or Sheets. Collaborate in real-time with colleagues or students, making it an easy tool for group projects.\n",
        "\n",
        "4. **Pre-installed Libraries:**\n",
        "Colab comes with many popular machine learning libraries pre-installed, such as TensorFlow, PyTorch, and scikit-learn, saving you time on setup.\n",
        "\n",
        "5. **Cloud Storage Integration:**\n",
        "Easily import datasets or export your trained models using Google Drive. Colab seamlessly integrates with Google Cloud, making data management and sharing straightforward.\n",
        "\n",
        "#### Getting Started:\n",
        "\n",
        "To begin your deep learning journey with Colab, simply follow these steps:\n",
        "\n",
        "1. **Open a Colab Notebook:**\n",
        "   - Go to [Google Colab](https://colab.research.google.com/).\n",
        "   - Create a new notebook or open an existing one.\n",
        "\n",
        "2. **Choose Runtime Type:**\n",
        "   - Navigate to \"Runtime\" in the menu.\n",
        "   - Select \"Change runtime type\" to choose between CPU, GPU, or TPU.\n",
        "\n",
        "3. **Run Code Cells:**\n",
        "   - Write your Python code in cells.\n",
        "   - Execute cells using the play button or `Shift + Enter`.\n",
        "\n",
        "4. **Save and Share:**\n",
        "   - Save your work on Google Drive or GitHub.\n",
        "   - Share your notebook link with others for collaboration."
      ],
      "metadata": {
        "id": "xQbQLKuEb7ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries used in this tutorial\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   math\n",
        "*   sys\n",
        "*   torch\n",
        "*   torchviz\n",
        "*   IPython\n",
        "\n",
        "** Conda has all of them except torchviz, we'll install it using pip install.\n"
      ],
      "metadata": {
        "id": "MkXBg9uEdI8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in colab setup only.\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "#clear display\n",
        "from IPython import display\n",
        "import time\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "lJDpu9D0dHzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ8suwGnNPWT"
      },
      "source": [
        "## Jupyter basics\n",
        "\n",
        "Jupyter notebooks consist mainly of code and markdown cells.\n",
        "The code cells contain code that is run by a `kernel`, an\n",
        "interpreter for some programming language, python in our case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xlBXFH7NPWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8c3f1f-195d-4131-a7a1-7749b7bf5436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bar\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# This is a code cell; it can contain arbitrary python code.\n",
        "\n",
        "foo = 'bar'\n",
        "print(foo)\n",
        "\n",
        "def the_answer():\n",
        "    return 42\n",
        "\n",
        "# The output of the last expression in a cell is shown\n",
        "2*the_answer()\n",
        "the_answer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkMyVbIkNPWV"
      },
      "source": [
        "Variables and functions defined in a code cell are available in subsequent cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Btdc3cJNPWV"
      },
      "outputs": [],
      "source": [
        "ans = the_answer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvCRYfrjNPWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4206a9-15c3-4151-a9fc-056196804df9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFJrCsSTNPWW"
      },
      "source": [
        "This is a markdown cell. You can use markdown syntax to format your text, and also include equations\n",
        "written in $\\LaTeX$:\n",
        "\n",
        "$$\n",
        "e^{i\\pi} - 1 = 0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xMam_5nNPWX"
      },
      "source": [
        "Other useful things to know about:\n",
        "* Managing runtimes\n",
        "* Restarting kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "toc-nb-collapsed": true,
        "id": "5qXtesdINPWY"
      },
      "source": [
        "## Basics of Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "toc-hr-collapsed": true,
        "toc-nb-collapsed": true,
        "id": "gXKG-s1aNPWX"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqoH8TZ0NPWX"
      },
      "source": [
        "Python is a great general-purpose programming language on its own and with the addition of a few\n",
        "popular libraries such as `numpy`, `scipy`, `pandas`, `scikit-learn`, `matplotlib` and others it becomes an\n",
        "effective scientific computing environment.\n",
        "\n",
        "Today it is also the most-used language for machine learning both in research and industry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUBtws1FNPWX"
      },
      "source": [
        "Recently many **Deep Learning frameworks** have emerged for python.\n",
        "Arguably the most notable ones in 2021 are **TensorFlow** (with the Keras frontend) and **PyTorch**.\n",
        "\n",
        "In this course we'll use PyTorch, which is currently [the leading DL framework](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry) for research.\n",
        "\n",
        "<center><img src=\"https://thegradient.pub/content/images/2019/10/number_medium.png\" width=\"700\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLjcvlo9NPWY"
      },
      "source": [
        "Many of you may have some experience with Python and numpy; for the rest of you, this notebook can serve as a quick crash course both on the Python programming language and on the use of PyTorch for scientific computing with tensors.\n",
        "\n",
        "However, we recommend getting up to speed with python using the numerous availble online resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAM4sZERNPWY"
      },
      "source": [
        "Credit: Parts of the Python tutorial here were adapted from the [CS231n Python tutorial](http://cs231n.github.io/python-numpy-tutorial/) by Justin Johnson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOjXY7TBNPWY"
      },
      "source": [
        "Python is a high-level, dynamically typed multiparadigm programming language. Python code is often said to be almost like pseudocode, since it allows you to express very powerful ideas in very few lines of code while being very readable. As an example, here is an implementation of the classic quicksort algorithm in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "peYYLVZGNPWZ"
      },
      "outputs": [],
      "source": [
        "def quicksort(arr):\n",
        "    if len(arr) <= 1:\n",
        "        return arr\n",
        "    pivot = arr[len(arr) // 2]\n",
        "    left = [x for x in arr if x < pivot]\n",
        "    middle = [x for x in arr if x == pivot]\n",
        "    right = [x for x in arr if x > pivot]\n",
        "    return quicksort(left) + middle + quicksort(right)\n",
        "\n",
        "print(quicksort([3,6,8,10,1,2,1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXCeQ03NPWZ"
      },
      "source": [
        "Python has great [documentation](https://docs.python.org/3)! Use it often."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyRyK_TDNPWZ"
      },
      "source": [
        "### Packages and modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEGW8vXxNPWa"
      },
      "source": [
        "A python **module** is simply a python file (`.py`), which can contain functions, classes and even top-level code.\n",
        "\n",
        "A **package** is a collection of modules within a directory. Python comes with a standard library which\n",
        "includes many useful packages.\n",
        "\n",
        "A package must be imported before use. They can be imported like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TheZ25FZNPWa"
      },
      "outputs": [],
      "source": [
        "# Import packages from the python standard library\n",
        "import math\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BYUx8vANPWb"
      },
      "source": [
        "### Basic data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVSKnQBVNPWb"
      },
      "source": [
        "#### Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ-qK-A_NPWb"
      },
      "source": [
        "Integers and floats work as you would expect from other languages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Nsi4FBUmNPWc"
      },
      "outputs": [],
      "source": [
        "x = 3\n",
        "print(x, type(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "7-Tm2ev-NPWc"
      },
      "outputs": [],
      "source": [
        "print(x + 1)  # Addition;\n",
        "print(x - 1)  # Subtraction;\n",
        "print(x * 2)  # Multiplication;\n",
        "print(x ** 2)  # Exponentiation;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "oRKk7wY8NPWc"
      },
      "outputs": [],
      "source": [
        "x += 1\n",
        "print(x)\n",
        "x *= 2\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ICjz3IFqNPWd"
      },
      "outputs": [],
      "source": [
        "y = 2.5\n",
        "print(type(y))\n",
        "print(y, y + 1, y * 2, y ** 2, y / 2, y // 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23nzsD82NPWd"
      },
      "source": [
        "Note that unlike many languages, Python does not have unary increment (x++) or decrement (x--) operators.\n",
        "\n",
        "Python also has built-in types for long integers and complex numbers; you can find all of the details in the [documentation](https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-long-complex)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKkOUaUfNPWd"
      },
      "source": [
        "#### Booleans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLc5w9eKNPWe"
      },
      "source": [
        "Python implements all of the usual operators for Boolean logic, but uses English words rather than symbols (`&&`, `||`, etc.):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "TNB_Zo0NNPWe"
      },
      "outputs": [],
      "source": [
        "t, f = True, False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQK8hMu7NPWe"
      },
      "source": [
        "Now we let's look at the operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "WKYsbVmUNPWe"
      },
      "outputs": [],
      "source": [
        "print(t and f) # Logical AND\n",
        "print(t or f ) # Logical OR\n",
        "print(not t  ) # Logical NOT\n",
        "print(t != f ) # Logical XOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCH-moICNPWf"
      },
      "source": [
        "#### Strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zj025bMyNPWf"
      },
      "outputs": [],
      "source": [
        "hello = 'hello'   # String literals can use single quotes\n",
        "world = \"world\"   # or double quotes; it does not matter.\n",
        "hello, len(hello)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "lwFwjlg9NPWf"
      },
      "outputs": [],
      "source": [
        "# String concatenation\n",
        "'aaa ' + 'bbb'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7L8I9oDNPWf"
      },
      "source": [
        "There are several way to created formatted strings, here are a couple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WltjaSBYNPWg"
      },
      "outputs": [],
      "source": [
        "s = 'hello'\n",
        "a = [1,2,3]\n",
        "\n",
        "# sprintf style string formatting\n",
        "print('%s %s: pi=%.5f' % (s, a, math.pi))\n",
        "\n",
        "# formatting with f-string literals (python 3.6+)\n",
        "print(f'{s} {a}: pi={math.pi:.5f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Iuf0JwNPWg"
      },
      "source": [
        "String objects have a bunch of useful methods; for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "i1DuYE6tNPWg"
      },
      "outputs": [],
      "source": [
        "s = \"hello\"\n",
        "print(s.capitalize() ) # Capitalize a string; prints \"Hello\"\n",
        "print(s.upper()      ) # Convert a string to uppercase; prints \"HELLO\"\n",
        "print(s.rjust(7)     ) # Right-justify a string, padding with spaces; prints \"  hello\"\n",
        "print(s.center(7)    ) # Center a string, padding with spaces; prints \" hello \"\n",
        "print(s.replace('l', '(ell)'))  # Replace all instances of one substring with another\n",
        "print('  world '.strip())  # Strip leading and trailing whitespace; prints \"world\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-OolOIgNPWh"
      },
      "source": [
        "You can find a list of all string methods in the [documentation](https://docs.python.org/3/library/stdtypes.html#string-methods)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1EZlo5tNPWh"
      },
      "source": [
        "### Containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoKC5oQHNPWh"
      },
      "source": [
        "Python includes several built-in container types: lists, dictionaries, sets, and tuples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66D54POiNPWi"
      },
      "source": [
        "#### Lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1p3cy69NPWi"
      },
      "source": [
        "A list is the Python equivalent of an array, but is resizeable and can contain elements of different types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "waFgiI93NPWi"
      },
      "outputs": [],
      "source": [
        "xs = [3, 1, 2]   # Create a list\n",
        "print(xs)\n",
        "print(xs[2], xs[-1]) # Negative indices count from the end of the list; prints \"2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "3cYEyq4NNPWi"
      },
      "outputs": [],
      "source": [
        "xs[2] = 'foo'    # Lists can contain elements of different types\n",
        "print(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "imtr_6ZpNPWi"
      },
      "outputs": [],
      "source": [
        "xs.append('bar') # Add a new element to the end of the list\n",
        "print(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "u2TNjVsuNPWi"
      },
      "outputs": [],
      "source": [
        "x = xs.pop()     # Remove and return the last element of the list\n",
        "x, xs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXJF5dkONPWi"
      },
      "source": [
        "#### Slicing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUihfx3mNPWj"
      },
      "source": [
        "In addition to accessing list elements one at a time, Python provides concise syntax to access sublists; this is known as slicing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Obr-8vBtNPWj"
      },
      "outputs": [],
      "source": [
        "nums = list(range(5))\n",
        "nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Oz0FwgBtNPWj"
      },
      "outputs": [],
      "source": [
        "nums[2:4]    # Get a slice from index 2 to 4 (exclusive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "yjNyuKPwNPWj"
      },
      "outputs": [],
      "source": [
        "nums[2:]     # Get a slice from index 2 to the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "jI-X4FK5NPWj"
      },
      "outputs": [],
      "source": [
        "nums[:2]     # Get a slice from the start to index 2 (exclusive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "JQ9bhF4mNPWk"
      },
      "outputs": [],
      "source": [
        "nums[:]      # Get a slice of the whole list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "gSPTiNo6NPWk"
      },
      "outputs": [],
      "source": [
        "nums[:-1]    # Slice indices can be negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv51kn_5NPWk"
      },
      "outputs": [],
      "source": [
        "nums[0:4:2]  # Can also specify slice step size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "bCaQxWzZNPWl"
      },
      "outputs": [],
      "source": [
        "nums[2:4] = [8, 9] # Assign a new sublist to a slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bomyMzLKNPWl"
      },
      "outputs": [],
      "source": [
        "# Delete elements from a list\n",
        "nums[0:1] = []\n",
        "del nums[-1]\n",
        "nums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqG6fnN_NPWl"
      },
      "source": [
        "#### Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6Ro6LJdNPWl"
      },
      "source": [
        "You can loop over the elements of a list like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0AItQCh3NPWm"
      },
      "outputs": [],
      "source": [
        "animals = ['cat', 'dog', 'monkey']\n",
        "for animal in animals:\n",
        "    print(animal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "296ovuR6NPWm"
      },
      "source": [
        "If you want access to the index of each element within the body of a loop, use the built-in `enumerate` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "cr7HWo1UNPWm"
      },
      "outputs": [],
      "source": [
        "animals = ['cat', 'dog', 'monkey']\n",
        "for idx, animal in enumerate(animals):\n",
        "    print(f'#{idx+1}: {animal}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6bljUYONPWm"
      },
      "source": [
        "#### List comprehensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ta2KStkNPWm"
      },
      "source": [
        "When programming, frequently we want to transform one type of data into another. As a simple example, consider the following code that computes square numbers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "42l8FD8rNPWn"
      },
      "outputs": [],
      "source": [
        "nums = [0, 1, 2, 3, 4]\n",
        "squares = []\n",
        "for x in nums:\n",
        "    squares.append(x ** 2)\n",
        "squares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6_DUn_PNPWn"
      },
      "source": [
        "You can make this code simpler using a list comprehension:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dAxlbiOLNPWn"
      },
      "outputs": [],
      "source": [
        "squares = [x ** 2 for x in nums]\n",
        "squares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y4NDDKfNPWn"
      },
      "source": [
        "List comprehensions can also contain conditions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "cS-10DJSNPWo"
      },
      "outputs": [],
      "source": [
        "even_squares = [x ** 2 for x in nums if x % 2 == 0]\n",
        "even_squares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9eBBfC4NPWo"
      },
      "source": [
        "List comprehensions can be nested:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KugXbxsSNPWo"
      },
      "outputs": [],
      "source": [
        "nums2 = [-1, 1]\n",
        "[x * y for x in nums for y in nums2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Fd-Z0NNPWp"
      },
      "source": [
        "#### Dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InTMAYHZNPWp"
      },
      "source": [
        "A dictionary stores (key, value) pairs. In other languages this is known as a `Map` or `Hash`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_qw74tWxNPWp"
      },
      "outputs": [],
      "source": [
        "d = {'cat': 'cute', 'dog': 'furry'}  # Create a new dictionary with some data\n",
        "print(d['cat'])       # Get an entry from a dictionary\n",
        "print('cat' in d)     # Check if a dictionary has a given key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "k4ZBT6U3NPWp"
      },
      "outputs": [],
      "source": [
        "d['fish'] = 'wet'    # Set an entry in a dictionary\n",
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atBy_pP7NPWq"
      },
      "outputs": [],
      "source": [
        "# Trying to access a non-existing key raises a KeyError\n",
        "try:\n",
        "    d['monkey']\n",
        "except KeyError as e:\n",
        "    print(e, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "mu0d-kr5NPWq"
      },
      "outputs": [],
      "source": [
        "print(d.get('monkey', 'N/A'))  # Get an element with a default\n",
        "print(d.get('fish', 'N/A'))    # Get an element with a default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dK4pnfigNPWr"
      },
      "outputs": [],
      "source": [
        "del d['fish']        # Remove an element from a dictionary\n",
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HOLjaemGNPWr"
      },
      "outputs": [],
      "source": [
        "# Iteration over keys\n",
        "d = {'person': 2, 'cat': 4, 'spider': 8}\n",
        "for animal in d:\n",
        "    print(f'A {animal} has {d[animal]} legs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "KCmGUkgzNPWs"
      },
      "outputs": [],
      "source": [
        "# Iterate over key-value pairs\n",
        "d = {'person': 2, 'cat': 4, 'spider': 8}\n",
        "for animal, num_legs in d.items():\n",
        "    print(f'A {animal} has {num_legs} legs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbfl8kzrNPWs"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary using the built-in dict() function\n",
        "dict(foo=1, bar=2, baz=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1RDOWcBNPWs"
      },
      "source": [
        "#### Dictionary comprehensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjwrN_LpNPWs"
      },
      "source": [
        "These are similar to list comprehensions, but allow you to easily construct dictionaries. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "J0KCqHbCNPWt"
      },
      "outputs": [],
      "source": [
        "nums = [0, 1, 2, 3, 4]\n",
        "even_num_to_square = {x: x ** 2 for x in nums if x % 2 == 0}\n",
        "even_num_to_square"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNNBh0WyNPWt"
      },
      "source": [
        "#### Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTvkceGFNPWu"
      },
      "source": [
        "A set is an unordered collection of distinct elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9OUdY1VkNPWu"
      },
      "outputs": [],
      "source": [
        "animals = {'cat', 'dog'}\n",
        "print(animals)\n",
        "print('cat' in animals )  # Check if an element is in a set\n",
        "print('fish' in animals) # prints \"False\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "AovzyQDDNPWu"
      },
      "outputs": [],
      "source": [
        "animals.add('fish') # Add an element to a set\n",
        "print('fish' in animals)\n",
        "len(animals) # Number of elements in a set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "B4zoMmAFNPWu"
      },
      "outputs": [],
      "source": [
        "animals.add('cat')       # Adding an element that is already in the set does nothing\n",
        "animals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPwGLq_zNPWu"
      },
      "source": [
        "_Loops_: Iterating over a set has the same syntax as iterating over a list; however since sets are unordered, you cannot make assumptions about the order in which you visit the elements of the set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "UORFbJ_KNPWv"
      },
      "outputs": [],
      "source": [
        "animals = {'cat', 'dog', 'fish'}\n",
        "for idx, animal in enumerate(animals):\n",
        "    print(f'#{idx}: {animal}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_vaSHSNNPWv"
      },
      "source": [
        "#### Set comprehensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lz4h7m_NPWv"
      },
      "source": [
        "Like lists and dictionaries, we can easily construct sets using set comprehensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "cwawXhFgNPWv"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "s = {int(sqrt(x)) for x in range(37)}\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vthkm2pwNPWw"
      },
      "source": [
        "#### Tuples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNcaTuQnNPWw"
      },
      "source": [
        "A tuple is an **immutable** ordered list of values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XYDQSW0NPWw"
      },
      "outputs": [],
      "source": [
        "t = (1, 2, 'three')\n",
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGTm7s3VNPWw"
      },
      "source": [
        "It can be used in ways similar to a list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFVzVtM5NPWw"
      },
      "outputs": [],
      "source": [
        "t[0:1], t[1:3], t[-1], len(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upyPMNjSNPWx"
      },
      "source": [
        "A tuple can be used a key in a dictionary and as an element of a sets, while **lists cannot**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "OtWW8N91NPWx"
      },
      "outputs": [],
      "source": [
        "d = {(x, x + 1): x for x in range(10)}  # Create a dictionary with tuple keys\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYJKMsPxNPWx"
      },
      "source": [
        "A tuple (and also a list) can be **unpacked**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sryQ7YV_NPWy"
      },
      "outputs": [],
      "source": [
        "one, two, three = t\n",
        "one, two, three"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEQa5OASNPWy"
      },
      "source": [
        "Note that when retuning multiple values from a function (or code block in a jupyter notebook, as above)\n",
        "your values get wrapped in a tuple, and the tuple is what's returned.\n",
        "Unpacking the return value of a function can make it seem as if multiple values were returned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRAoLyHcNPWy"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwJ6wF_RNPWy"
      },
      "source": [
        "Python functions are defined using the `def` keyword. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wm1SRKDNNPWy"
      },
      "outputs": [],
      "source": [
        "def sign(x):\n",
        "    if x > 0:\n",
        "        return 'positive'\n",
        "    elif x < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'zero'\n",
        "\n",
        "for x in [-1, 0, 1]:\n",
        "    print(sign(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY7iqLt2NPWz"
      },
      "source": [
        "We will often define functions to take optional keyword arguments, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "fNbulFvbNPW0"
      },
      "outputs": [],
      "source": [
        "def hello(name, loud=False):\n",
        "    if loud:\n",
        "        print('HELLO, %s' % name.upper())\n",
        "    else:\n",
        "        print('Hello, %s!' % name)\n",
        "\n",
        "hello('Bob')\n",
        "hello('Fred', loud=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-bTIFveNPW0"
      },
      "source": [
        "#### Positional and Keyword arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqa-SgedNPW0"
      },
      "source": [
        "Python functions are very flexible in the way they accept arguments. Both positional (regular) and keyword\n",
        "arguments are supported and can be mixed in the same definition. Additionally, extra arguments can be passed in with the `*args` and `**kwargs` constructs.\n",
        "\n",
        "Here's a function with three positional arguments and three keyword arguments which also accepts extra\n",
        "positional and keyword arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOReh-UyNPW0"
      },
      "outputs": [],
      "source": [
        "def myfunc(a1, a2, a3, *extra_args, kw1='foo', kw2='bar', kw3=3, **extra_kwargs):\n",
        "    print(f'Got positional args: {(a1, a2, a3)}')\n",
        "    print(f'Got keyword args   : {dict(kw1=kw1, kw2=kw3, kw3=kw3)}')\n",
        "    print(f'Got extra positional args: {extra_args}')\n",
        "    print(f'Got extra keyword args: {extra_kwargs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYgzzIpqNPW0"
      },
      "source": [
        "It can be called in many ways:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlfF_wctNPW0"
      },
      "outputs": [],
      "source": [
        "myfunc(1,2,3,4,5,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e78Bm74hNPW0"
      },
      "outputs": [],
      "source": [
        "my_args = [1,2,3,4]\n",
        "myfunc(*my_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkw_Bt8bNPW0"
      },
      "outputs": [],
      "source": [
        "myfunc(1,2,3, kw3=3, kw2=2, foo='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN07LLkgNPW0"
      },
      "outputs": [],
      "source": [
        "my_kwargs = dict(kw1=1, kw2=2, kw3=3, kw4=4)\n",
        "myfunc(1,2,3, **my_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCTXAnjsNPW1"
      },
      "source": [
        "Note that keyword args can be omitted, while positional args cannot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLkQL7vrNPW1"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    myfunc(1,2)\n",
        "except TypeError as e:\n",
        "    print(e, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bls8DFvKNPW1"
      },
      "source": [
        "### Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MYswsqZNPW1"
      },
      "source": [
        "The syntax for defining classes in Python is straightforward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "5YpodaBzNPW1"
      },
      "outputs": [],
      "source": [
        "class Greeter:\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, name):\n",
        "        self.name = name  # Create an instance variable\n",
        "\n",
        "    # Instance method\n",
        "    def greet(self, loud=False):\n",
        "        if loud:\n",
        "            print('HELLO, %s!' % self.name.upper())\n",
        "        else:\n",
        "            print('Hello, %s' % self.name)\n",
        "\n",
        "g = Greeter('Fred')  # Construct an instance of the Greeter class\n",
        "g.greet()            # Call an instance method\n",
        "g.greet(loud=True)   # Call an instance method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74OYGGt5NPW2"
      },
      "source": [
        "Classes can implement special **magic functions** that enable them to be integrated nicely with other python code. Magic functions have special names that start and end with `__`.\n",
        "\n",
        "For example, here's a class that can be indexed with `[]` and iterated over with a `for` loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM4LrD3YNPW2"
      },
      "outputs": [],
      "source": [
        "class ExampleCollection(object):\n",
        "    def __init__(self):\n",
        "        self.items = [100, 200, 300]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.items[idx]\n",
        "\n",
        "    def __iter__(self):\n",
        "        class ExampleIter():\n",
        "            def __init__(self, collection):\n",
        "                self.idx = 0\n",
        "                self.collection = collection\n",
        "\n",
        "            def __next__(self):\n",
        "                if self.idx >= len(self.collection):\n",
        "                    raise StopIteration()\n",
        "                x = self.collection[self.idx]\n",
        "                self.idx += 1\n",
        "                return x\n",
        "\n",
        "        return ExampleIter(self)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDJNjmR2NPW2"
      },
      "outputs": [],
      "source": [
        "example = ExampleCollection()\n",
        "print('length=', len(example)) # invokes __len__\n",
        "print('example[0]=', example[0]) # invokes __getitem__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QepRmNObNPW3"
      },
      "outputs": [],
      "source": [
        "for x in example: # invokes __iter__ and it's __next__\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMExhT_VNPW3"
      },
      "source": [
        "Many other magic functions exist. Consult the docs and see if you can catch 'em all!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Ry2cWB6BNPW3"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MkMxt8CNPW3"
      },
      "source": [
        "PyTorch is a relatively new yet widely used deep learning framework for python.\n",
        "\n",
        "It can also be used as a general scientific computing library, as it provides a high-performance multidimensional array object, with GPU support.\n",
        "\n",
        "We'll refer to such n-dimentional arrays as **tensors** in accordance with the deep learning terminology.\n",
        "Crucially, pytorch supports **automatic differentiation** through arbitrary computations performed on its tensors.\n",
        "\n",
        "During the course we'll use it extensively and learn many parts of its API.\n",
        "You should also familiarize yourself with the [PyTorch Documentation](https://pytorch.org/docs/stable/) as it will greatly assist you when implementing your own models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzURoZFDNPW3"
      },
      "source": [
        "This notebook will show only **a small part** of PyTorch's API, the `Tensor` class.\n",
        "This class is very similar to numpy's `ndarray`, and provides much of the same functionality.\n",
        "However, it also has two important distinctions:\n",
        "- Support for GPU computations.\n",
        "- Can store extra data needed for implementing **automatic differentiation** used for back propagation:\n",
        "    - A tensor of the same dimentions containing the gradient of this tensor w.r.t. some scalar (e.g. loss).\n",
        "    - A node representing an operation in the computational graph that produced this tensor.\n",
        "\n",
        "In the next tutorials we will examine these concepts further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r75rOJYCNPW4"
      },
      "source": [
        "This notebook will show some brief examples, just to get a feel for it and compare it to the usual numpy `ndarray`s.\n",
        "\n",
        "You will be using both PyTorch tensors and numpy `ndarray`s extensively throughout the course homework assignments, and in general when implementing deep learning algorithms.\n",
        "Although we'll mainly use **PyTorch** tensors for implementing our Deep Learning systems, it's still important to be proficient with `numpy`, since:\n",
        "1. They concepts are very similar. Understanting one will help you quickly be proficient with the other.\n",
        "1. You'll find that you need to switch between the two when working with read DL systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMDvqcu6NPW4"
      },
      "source": [
        "To use pytorch, we first need to import the `torch` package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "id": "k9mhV3m0NPW4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "OQ_y3JT5AaeJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a36bce5-deab-430c-e4e9-e1aeedc126fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkvEh93eNPW4"
      },
      "source": [
        "### Tensors: n-dimentional arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUXrYg1JNPW5"
      },
      "source": [
        "A tensor represents an n-dimentional grid of values, all of the same type, and is indexed by a tuple of nonnegative integers. The name \"tensor\" is a generalization of concepts you already know.\n",
        "For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor.\n",
        "\n",
        "- The **rank** of the tensor is the number of dimensions it has.\n",
        "- The **shape** of a tensor is a tuple of integers giving the number of elements along each dimension.\n",
        "\n",
        "Most common functions you know from numpy can be used on tensors as well.\n",
        "Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don't need it too often."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fv-glCMNPW5"
      },
      "source": [
        "We can initialize tensors from nested Python lists, and access elements using square brackets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "id": "Dw2dcJKoNPW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80740824-fcda-4470-9b7a-a7cb7b69fed5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "a = torch.tensor([1, 2, 3.])  # Create a rank 1 array\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "4v1UPxYFNPW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23fd947-0e3c-4c0e-8c25-eeae738b0237"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Indexing always returns tensors\n",
        "a[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx6qaCKpNPW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d218e1a7-0962-42be-ade8-8397e0f101b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Use .item() to get a python scalar\n",
        "a[0].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMwcxJbXNPW6"
      },
      "source": [
        "Two very important properties of any tensor are its `shape` and `dtype`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "id": "AJRNGOzoNPW6"
      },
      "outputs": [],
      "source": [
        "def print_arr(arr, pre_text=''):\n",
        "    print(f'shape={tuple(arr.shape)} dtype={arr.dtype}:')\n",
        "    print(f'{pre_text}{arr}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "5DbRkSnoNPW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593917f5-41d5-44c9-df73-acf3a680f7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3,) dtype=torch.float32:\n",
            "tensor([1., 2., 3.])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "id": "ihnTkFhUNPW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0da5c26-c43d-4cf6-eacf-20957dec851b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "a[0] = 5                 # Change an element of the array\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can obtain the shape of a tensor in the same way as in numpy (`x.shape`), or using the `.size` method:"
      ],
      "metadata": {
        "id": "wCeH8b8xtD6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "a = torch.rand(2, 3, 4)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "yv2ZY-jotbOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61574e7-9db1-41a1-b760-2c251e5e395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4950, 0.2661, 0.2261, 0.4103],\n",
            "         [0.9319, 0.1015, 0.8076, 0.6862],\n",
            "         [0.4194, 0.2464, 0.2088, 0.4357]],\n",
            "\n",
            "        [[0.6235, 0.6372, 0.8816, 0.5087],\n",
            "         [0.2533, 0.9897, 0.9401, 0.7171],\n",
            "         [0.1993, 0.6503, 0.3754, 0.8313]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = a.shape\n",
        "print(\"Shape:\", a.shape)\n",
        "\n",
        "size = a.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = a.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ],
      "metadata": {
        "id": "JjpIlHWLtDgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567ccd99-bcf8-40af-d404-73eb6c382da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([2, 3, 4])\n",
            "Size: torch.Size([2, 3, 4])\n",
            "Size: 2 3 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "id": "Y2VbHV90NPW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af37dc3-4f1d-4a55-92d7-192ae243e628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2, 3) dtype=torch.int64:\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6]],\n",
            "\n",
            "        [[11, 22, 33],\n",
            "         [44, 55, 66]]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "b = torch.tensor([[[1,2,3],[4,5,6]], [[11, 22, 33], [44, 55, 66]]])   # Create a rank 3 array\n",
        "print_arr(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a general n-dimensional tensor, `b[i, j, k, ...]` accesses a specific element based on its position in each dimension, where i, j, k, etc., are zero-based indices for each dimension.\n",
        "\n",
        "For an n-dimensional tensor, you interpret each index as follows:\n",
        "*   `i`: Index in the first dimension (e.g., row in 2D, depth in 3D).\n",
        "*   `j`: Index in the second dimension (e.g., column in 2D, row in 3D).\n",
        "*   `k`: Index in the third dimension, and so forth.\n",
        "\n",
        "\n",
        "\n",
        "For example, in a 3D tensor (e.g., a tensor with shape `[depth, rows, columns]`):\n",
        "\n",
        "`b[i, j, k]` accesses the element located at the i-th depth slice, j-th row, and k-th column."
      ],
      "metadata": {
        "id": "VKqhG5cDVkm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "id": "kjFFEuzRNPW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8fd883-6eea-44de-d245-d8086a5ce3e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n",
            "tensor(6)\n",
            "tensor(22)\n"
          ]
        }
      ],
      "source": [
        "# Given b is a 3D tensor with shape [depth, rows, columns].\n",
        "\n",
        "# Access the element at depth=0, row=0, column=0\n",
        "print(b[0, 0, 0])  # Accesses the element in the first depth slice, first row, first column\n",
        "\n",
        "# Access the element at depth=0, row=1, column=2\n",
        "print(b[0, 1, 2])  # Accesses the element in the first depth slice, second row, third column\n",
        "\n",
        "# Access the element at depth=1, row=0, column=1\n",
        "print(b[1, 0, 1])  # Accesses the element in the second depth slice, first row, second column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDB4fiTrNPW8"
      },
      "source": [
        "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory.\n",
        "To directly assign values to the tensor during initialization, there are many alternatives including:\n",
        "\n",
        "* `torch.zeros`: Creates a tensor filled with zeros\n",
        "* `torch.ones`: Creates a tensor filled with ones\n",
        "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
        "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "* `torch.full`: Creates a tensor of the specified size filled with a specified value.\n",
        "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
        "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide\n",
        "* `torch.eye`: Creates an identity matrix, i.e., a tensor with ones on the diagonal and zeros elsewhere.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "e3a_3Sc4NPW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b061def-f0ff-4f2f-b7be-ae9431f79538"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "torch.zeros((2, 2))  # Create an array of all zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "uY40dylVNPW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0422d17e-236d-41cd-9c90-f47793aac596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "torch.ones((1, 10))   # Create an array of all ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Nrb20_dPNPXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9edb1de6-88eb-4e9e-988f-159d24bf5d28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.2000, 7.2000, 7.2000],\n",
              "        [7.2000, 7.2000, 7.2000],\n",
              "        [7.2000, 7.2000, 7.2000]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "torch.full((3, 3), 7.2) # Create a constant array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "D1Wh3j3fNPXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5024ecc-ffd6-441a-cea3-37c7ba4fd997"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0, 0],\n",
              "        [0, 1, 0, 0],\n",
              "        [0, 0, 1, 0],\n",
              "        [0, 0, 0, 1]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "torch.eye(4, dtype=torch.int) # Create an identity matrix of integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ZGS9UDKKNPXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b2a447-de76-462d-a758-09e0c045753c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3995, 0.9339, 0.3191],\n",
              "         [0.4145, 0.7216, 0.2637],\n",
              "         [0.9357, 0.4412, 0.9199],\n",
              "         [0.9731, 0.0884, 0.1306]],\n",
              "\n",
              "        [[0.3607, 0.5795, 0.9463],\n",
              "         [0.5126, 0.3313, 0.9309],\n",
              "         [0.3766, 0.1333, 0.5225],\n",
              "         [0.9910, 0.0877, 0.8627]],\n",
              "\n",
              "        [[0.3386, 0.9977, 0.7395],\n",
              "         [0.1263, 0.3367, 0.5406],\n",
              "         [0.4243, 0.9504, 0.0715],\n",
              "         [0.8552, 0.4077, 0.7534]],\n",
              "\n",
              "        [[0.7129, 0.9001, 0.5558],\n",
              "         [0.6862, 0.2317, 0.6383],\n",
              "         [0.6033, 0.0994, 0.1707],\n",
              "         [0.8280, 0.5969, 0.4900]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "t = torch.rand((4,4,3)) # Create a 3d-array filled with U[0,1] random values\n",
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "wfwpubO_NPXH"
      },
      "source": [
        "#### Array rank\n",
        "\n",
        "In `torch` **rank** means **number of dimensions**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae53MTNvNPXH"
      },
      "source": [
        "**rank-0** arrays are scalars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXR9qYVXNPXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8484eb-a8f8-49da-b256-1435d59897da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=() dtype=torch.int64:\n",
            "17\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a0 = torch.tensor(17)\n",
        "print_arr(a0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZJyoqTZNPXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0fbe7f-5d47-4555-a2ee-174236e56c26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Get scalar as a python float\n",
        "a0.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCTmY2lkNPXI"
      },
      "source": [
        "**rank-1** arrays of length `n` have a shape of `(n,)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uKE3725NPXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a5925b-b246-49a2-cc5a-74b4f0a6573e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3,) dtype=torch.int64:\n",
            "tensor([1, 2, 3])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# A rank-1 array\n",
        "a1 = torch.tensor([1,2,3])\n",
        "\n",
        "print_arr(a1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IWSoxNAeNPXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71b2322-ca1f-4641-a8af-9c56ea724558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(1,) dtype=torch.float32:\n",
            "tensor([3.1400])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# A rank-1 array scalar\n",
        "print_arr(torch.tensor([3.14]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM4fsBT3NPXJ"
      },
      "source": [
        "**rank-2** arrays have a shape of `(n,m)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcX7-angNPXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59dd9371-e5b6-4884-9509-dc5b15b3efab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 3) dtype=torch.int64:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a2 = torch.tensor([[1,2,3], [4,5,6]])\n",
        "\n",
        "print_arr(a2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-03-25T08:17:54.396587Z",
          "iopub.status.busy": "2021-03-25T08:17:54.395962Z",
          "iopub.status.idle": "2021-03-25T08:17:54.415353Z",
          "shell.execute_reply": "2021-03-25T08:17:54.414781Z"
        },
        "id": "Of87QRSbNPXJ"
      },
      "source": [
        "A column vector is also rank-2!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJS3vsMiNPXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e912390b-08ac-4ef7-97a6-43c916e1e9ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3, 1) dtype=torch.int64:\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a_col = a1.reshape(-1, 1)\n",
        "\n",
        "print_arr(a_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-03-25T08:17:54.418531Z",
          "iopub.status.busy": "2021-03-25T08:17:54.418004Z",
          "iopub.status.idle": "2021-03-25T08:17:54.433799Z",
          "shell.execute_reply": "2021-03-25T08:17:54.434351Z"
        },
        "id": "3VhBhLemNPXK"
      },
      "source": [
        "And a row vector is also rank-2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_oelj6cNPXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3b2250-5c55-43e8-90f5-5499ab88db6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(1, 3) dtype=torch.int64:\n",
            "tensor([[1, 2, 3]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a_row = a1.reshape(1, -1)\n",
        "\n",
        "print_arr(a_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh5LQLsDNPXK"
      },
      "source": [
        "**rank-k** arrays have a shape of `(n1,...,nk)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwIoigh9NPXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6281214a-ff93-44f0-85f8-dee42bc8299c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 3, 4) dtype=torch.float32:\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(torch.zeros((2,3,4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "vnZDU3jANPXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8fc188-0cd2-4040-deba-45e970f56410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2, 2, 2) dtype=torch.float32:\n",
            "tensor([[[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(torch.ones((2,2,2,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BHHH6uTNPXL"
      },
      "source": [
        "### Tensor math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-50mGRGMNPXL"
      },
      "source": [
        "#### Elementwise operations\n",
        "Basic mathematical functions **operate elementwise** on arrays, and are available both as operator overloads and as functions in the `torch` module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "JC5xO2QANPXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b045f73a-9e73-49b2-c6b4-b35b7fff1aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]])\n",
            "\n",
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1,2],[3,4]], dtype=torch.float)\n",
        "y = torch.tensor([[5,6],[7,8]], dtype=torch.float)\n",
        "\n",
        "# Elementwise basic math\n",
        "print_arr(x + y)\n",
        "print_arr(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-gD2E7djNPXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75752989-d221-4365-cd8f-ca2efef61691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[-4., -4.],\n",
            "        [-4., -4.]])\n",
            "\n",
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[-4., -4.],\n",
            "        [-4., -4.]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(x - y)\n",
        "print_arr(torch.sub(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": false,
        "id": "0f8nI3uvNPXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92ba73d-6f70-4336-b490-c1474a50f3c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[ 5., 12.],\n",
            "        [21., 32.]])\n",
            "\n",
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[ 5., 12.],\n",
            "        [21., 32.]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(x * y)\n",
        "print_arr(torch.mul(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "FJBMemvSNPXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077efba3-b803-4024-9325-205399ec917f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[0.2000, 0.3333],\n",
            "        [0.4286, 0.5000]])\n",
            "\n",
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[0.2000, 0.3333],\n",
            "        [0.4286, 0.5000]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(x / y)\n",
        "print_arr(torch.div(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0e26hX8vNPXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161b2aa3-9eb7-490b-c4d9-b777011aab36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[1.0000, 1.4142],\n",
            "        [1.7321, 2.0000]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Elementwise functions\n",
        "print_arr(torch.sqrt(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_RN2yvASNPXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b891ea-0d78-45d8-dbe1-73fcfbeaf68b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[ 2.7183,  7.3891],\n",
            "        [20.0855, 54.5981]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(torch.exp(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "k0xnwn5_NPXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80bae3f-2efe-4fec-a8fa-aee463a4481e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.float32:\n",
            "tensor([[0.0000, 0.6931],\n",
            "        [1.0986, 1.3863]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(torch.log(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydf2mfbDNPXO"
      },
      "source": [
        "There are of course many more elementwise operations inmplemented by `torch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJKp3Mu0NPXO"
      },
      "source": [
        "#### Inner and outer products\n",
        "\n",
        "Other commonly used operations include matrix multiplications, which are essential for neural networks.\n",
        "Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$.\n",
        "There are multiple ways and functions to perform matrix multiplication, some of which:\n",
        "\n",
        "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions.\n",
        "If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product.\n",
        "For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)).\n",
        "Can also be written as `a @ b`, similar to numpy. Or as `a dot b` for 1d tensors only.\n",
        "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
        "* `torch.bmm`: Performs the matrix product with a support batch dimension.\n",
        "If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
        "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention.\n",
        "Explanation of the Einstein sum can be found in assignment 1.\n",
        "\n",
        "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dmoZgm7bNPXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17bfa5fe-e9e3-43ed-f9b3-6b7e7a750120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(219)\n",
            "tensor(219)\n",
            "tensor(219)\n"
          ]
        }
      ],
      "source": [
        "v = torch.tensor([9, 10])\n",
        "w = torch.tensor([11, 12])\n",
        "\n",
        "# Inner product of vectors\n",
        "# This computes the dot product of vectors v and w:\n",
        "# (9 * 11) + (10 * 12) = 99 + 120 = 219\n",
        "print(torch.matmul(v, w))  # torch.matmul works for 1D tensors by performing an inner product\n",
        "print(torch.dot(v, w))      # torch.dot is specifically for 1D tensors (vectors) and performs the same inner product\n",
        "print(v @ w)                # @ is syntactic sugar for matmul and works for inner product in 1D\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([[0, 1, 2],\n",
        "                  [3, 4, 5]])\n",
        "\n",
        "w = torch.tensor([[0, 1, 2],\n",
        "                  [3, 4, 5],\n",
        "                  [6, 7, 8]])\n",
        "\n",
        "# Matrix multiplication of 2D tensors v and w\n",
        "# v has shape (2, 3) and w has shape (3, 3)\n",
        "# The result will have shape (2, 3) because it multiplies the 2x3 matrix by a 3x3 matrix.\n",
        "# Each element in the result is computed as the dot product of the rows of v and columns of w:\n",
        "#\n",
        "# For example, the top-left element (0,0) of the result is:\n",
        "# (0 * 0) + (1 * 3) + (2 * 6) = 0 + 3 + 12 = 15\n",
        "#\n",
        "# Similarly, other elements are calculated by performing a dot product of each row of v with each column of w.\n",
        "print(torch.matmul(v, w))"
      ],
      "metadata": {
        "id": "Y0Vv3cY0lBrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dff21f3-421b-481c-e334-8b1ab5e62d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[15, 18, 21],\n",
            "        [42, 54, 66]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suYb9__fNPXP"
      },
      "source": [
        "Rank-1 arrays arrays are somewhat special in that `torch` can treat them both as column or as row vectors.\n",
        "Arrays of different rank have different semantics when using them in vector-vector or vector-matrix products, so always make sure you know what shapes you're working with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMcyZz-oNPXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3db926c-2b39-4d22-dbf8-1b6f59134008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3,) dtype=torch.int64:\n",
            "a1\t\ttensor([1, 2, 3])\n",
            "\n",
            "shape=(1, 3) dtype=torch.int64:\n",
            "a_row\t\ttensor([[1, 2, 3]])\n",
            "\n",
            "shape=(3, 1) dtype=torch.int64:\n",
            "a_col\t\ttensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(a1, 'a1\\t\\t')\n",
        "print_arr(a_row, 'a_row\\t\\t')\n",
        "print_arr(a_col, 'a_col\\t\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb98fW6LNPXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d672982-25b2-4d24-b186-3fc111589742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=() dtype=torch.int64:\n",
            "a1 @ a1 =\t14\n",
            "\n",
            "shape=(1,) dtype=torch.int64:\n",
            "a_row @ a1 =\ttensor([14])\n",
            "\n",
            "shape=(1,) dtype=torch.int64:\n",
            "a1 @ a_col =\ttensor([14])\n",
            "\n",
            "shape=(1, 1) dtype=torch.int64:\n",
            "a_row @ a_col =\ttensor([[14]])\n",
            "\n",
            "shape=(3, 3) dtype=torch.int64:\n",
            "a_col @ a_row =\n",
            "tensor([[1, 2, 3],\n",
            "        [2, 4, 6],\n",
            "        [3, 6, 9]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inner products, but output dimenstions are different\n",
        "print_arr(torch.matmul(a1, a1), 'a1 @ a1 =\\t')\n",
        "assert torch.matmul(a1, a1) == a1 @ a1\n",
        "\n",
        "print_arr(torch.matmul(a_row, a1), 'a_row @ a1 =\\t')\n",
        "assert torch.matmul(a_row, a1) == a_row @ a1\n",
        "\n",
        "print_arr(torch.matmul(a1, a_col), 'a1 @ a_col =\\t')\n",
        "assert torch.matmul(a1, a_col) == a1 @ a_col\n",
        "\n",
        "print_arr(torch.matmul(a_row, a_col), 'a_row @ a_col =\\t')\n",
        "assert torch.matmul(a_row, a_col) == a_row @ a_col\n",
        "\n",
        "# Outer product\n",
        "print_arr(torch.matmul(a_col, a_row), 'a_col @ a_row =\\n')\n",
        "assert torch.all(torch.matmul(a_col, a_row) == a_col @ a_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWc7iB7ANPXQ"
      },
      "source": [
        "#### Non-elementwise operations\n",
        "\n",
        "Torch provides many useful functions for performing computations on arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zwZYRJWZNPXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335c77bb-e291-45f6-d776-92862057b202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 3) dtype=torch.float32:\n",
            "tensor([[1., 2., 3.],\n",
            "        [3., 4., 5.]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1,2,3],[3,4,5]], dtype=torch.float)\n",
        "print_arr(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true,
        "id": "AxwCPKNgNPXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6f0c7d-938b-4540-87c2-f5ec61ede23b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=() dtype=torch.float32:\n",
            "18.0\n",
            "\n",
            "shape=(3,) dtype=torch.float32:\n",
            "tensor([2., 3., 4.])\n",
            "\n",
            "shape=(2,) dtype=torch.float32:\n",
            "tensor([2., 4.])\n",
            "\n",
            "shape=(2,) dtype=torch.float32:\n",
            "tensor([ 6., 60.])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_arr(torch.sum(x))  # Compute sum of all elements\n",
        "print_arr(torch.mean(x, dim=0))  # Compute mean of each column\n",
        "print_arr(torch.mean(x, dim=1))  # Compute mean of each row\n",
        "print_arr(torch.prod(x, dim=1)) # Compute product of each row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkDs-fufNPXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a2a0d4-8ae2-4ace-9cd7-dc39a5345fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(1, 3) dtype=torch.float32:\n",
            "tensor([[2., 3., 4.]])\n",
            "\n",
            "shape=(2, 1) dtype=torch.float32:\n",
            "tensor([[2.],\n",
            "        [4.]])\n",
            "\n",
            "shape=(1, 3) dtype=torch.float32:\n",
            "tensor([[ 3.,  8., 15.]])\n",
            "\n",
            "shape=(2, 1) dtype=torch.float32:\n",
            "tensor([[ 6.],\n",
            "        [60.]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# In many cases, it's useful to aggregate but keep the original rank\n",
        "print_arr(torch.mean(x, dim=0, keepdim=True))\n",
        "print_arr(torch.mean(x, dim=1, keepdim=True))\n",
        "\n",
        "print_arr(torch.prod(x, dim=0, keepdim=True))\n",
        "print_arr(torch.prod(x, dim=1, keepdim=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KbE7JadNPXR"
      },
      "source": [
        "You can find the full list of mathematical functions provided by torch in the [documentation](https://pytorch.org/docs/stable/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "kNSfqQVqNPXR"
      },
      "source": [
        "### Indexing\n",
        "\n",
        "We often have the situation where we need to select a part of a tensor.\n",
        "Indexing works just like in numpy, so let's try it:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "DZSyOUKtT8dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfc5d1c-7e76-4c56-fc28-7a4c8f4fd58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:, 1])  # Second column"
      ],
      "metadata": {
        "id": "XVIDmW_RT8iM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816ad5b9-950c-405c-c7c9-a2d00b8b7061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 5, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])  # First row"
      ],
      "metadata": {
        "id": "0JiBvj4QUQeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ec48b2-fab3-4ef2-9abb-022aae10dd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:2, -1])  # First two rows, last column"
      ],
      "metadata": {
        "id": "X68J-7z9UQiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa14575-af25-4ab8-a478-f0b2af780844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1:3, :])  # Middle two rows"
      ],
      "metadata": {
        "id": "jtxKlNkaUSvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293459b1-2520-4b9f-b624-8888835768a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix08V_rRNPXS"
      },
      "source": [
        "**More about slicing**\n",
        "\n",
        "Similar to Python lists, tensors can be sliced. Since they may be multidimensional, you must specify **a slice for each dimension** of the array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "KYEFcbEDNPXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d2f176-a74a-4337-f8f3-cef6ac4457d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3, 4) dtype=torch.int64:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "\n",
        "print_arr(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "w65I1OkQNPXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a59dd5-5e45-40a9-f340-5bb2255f342e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.int64:\n",
            "tensor([[2, 3],\n",
            "        [6, 7]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "b = a[:2, 1:3]\n",
        "\n",
        "print_arr(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI7qlapINPXS"
      },
      "source": [
        "A slice of an array is a **view** into the same in-memory data, so modifying it will modify the original array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "mjiuUu6qNPXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a11796-ca93-4c5f-e2fd-a102a3ebc417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    1, 77777,     3,     4],\n",
              "        [    5,     6,     7,     8],\n",
              "        [    9,    10,    11,    12]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Changing a view\n",
        "b[0, 0] = 77777\n",
        "\n",
        "# ...modifies original\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_pQanZDNPXT"
      },
      "source": [
        "You can also mix integer indexing with slice indexing.\n",
        "However, doing so will yield an array of **lower rank** than the original array.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU6EoAueNPXT"
      },
      "source": [
        "Two ways of accessing the data in the middle row of the array.\n",
        "- Mixing integer indexing with slices yields an array of lower rank\n",
        "- Using only slices yields an array of the same rank as the original array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "XZarg5lANPXT"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "08pIexwMNPXT"
      },
      "outputs": [],
      "source": [
        "row_r1 = a[1, :]    # Rank 1 view of the second row of a\n",
        "row_r2 = a[1:2, :]  # Rank 2 view of the second row of a\n",
        "row_r3 = a[[1], :]  # Rank 2 view of the second row of a\n",
        "\n",
        "print_arr(row_r1)\n",
        "print_arr(row_r2)\n",
        "print_arr(row_r3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "cpB8smKBNPXU"
      },
      "outputs": [],
      "source": [
        "# We can make the same distinction when accessing columns of an array:\n",
        "col_r1 = a[:, 1]    # Rank 1 view of the second column of a\n",
        "col_r2 = a[:, 1:2]  # Rank 2 view of the second column of a\n",
        "\n",
        "print_arr(col_r1)\n",
        "print_arr(col_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3a6Sk5wNPXU"
      },
      "source": [
        "**Integer-array indexing**\n",
        "\n",
        "- When you slice, the resulting array view will always be a subarray of the original array.\n",
        "- Integer array indexing allows you to construct arbitrary arrays using the data from another array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "mPgqe7clNPXU"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([[1,2], [3, 4], [5, 6]])\n",
        "print_arr(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "L94IfQr1NPXV"
      },
      "outputs": [],
      "source": [
        "# An example of integer array indexing.\n",
        "# The returned array will have shape (3,)\n",
        "print_arr(a[ [0, 1, 2], [0, 1, 0] ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Fze-HEp6NPXV"
      },
      "outputs": [],
      "source": [
        "# The above example of integer array indexing is equivalent to this:\n",
        "print_arr(torch.tensor([a[0, 0], a[1, 1], a[2, 0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYdfX3aINPXW"
      },
      "source": [
        "One useful trick with integer array indexing is selecting or mutating one element from each row of a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_OPmvEkCNPXW"
      },
      "outputs": [],
      "source": [
        "# Create a new array from which we will select elements\n",
        "a = torch.tensor([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "i-Sk9DM4NPXW"
      },
      "outputs": [],
      "source": [
        "# Create an array of column indices (notice it can repeat)\n",
        "col_idx = torch.tensor([0, 2, 0, 1])\n",
        "\n",
        "# Select one element from each row of a using the indices in b\n",
        "a[torch.arange(4), col_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "pArCQ96vNPXW"
      },
      "outputs": [],
      "source": [
        "# Mutate one element from each row of a using the indices in b\n",
        "a[torch.arange(4), col_idx] += 1000\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2H7RGFkNPXW"
      },
      "source": [
        "**Boolean array indexing**\n",
        "\n",
        "This type of indexing is used to select the elements of an array that satisfy some condition\n",
        "(similar to MATLAB's logical indexing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Qt3ErZ5sNPXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37b1056-0b8a-49ff-c8bf-3bcfd00910fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3, 2) dtype=torch.int64:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1,2], [3, 4], [5, 6]])\n",
        "print_arr(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Lt-RgguJNPXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc9ca04-42a2-449d-93b4-1ba4e675e64d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False],\n",
              "        [ True,  True],\n",
              "        [ True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Find the elements that are bigger than 2;\n",
        "# this returns a numpy array of Booleans of the same\n",
        "# shape as a, where each slot of bool_idx tells\n",
        "# whether that element of a is > 2.\n",
        "bool_idx = (a > 2)\n",
        "bool_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ojQiNGWyNPXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600a6ff2-1914-4777-9fa1-84b57c248756"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# We use boolean array indexing to construct a rank 1 array\n",
        "# consisting of the elements of a corresponding to the True values\n",
        "# of bool_idx\n",
        "a[a>2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7fGpE3MNPXX"
      },
      "source": [
        "### Datatypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x09q6EWCNPXY"
      },
      "source": [
        "Every tensor is a grid of elements of the same type. `Pytorch` provides a large set of numeric datatypes that you can use to construct arrays.\n",
        "Pytorch tries to guess a datatype when you create an array, but functions that construct arrays usually also include an optional argument to explicitly specify the datatype.\n",
        "\n",
        "Heres a list of commonly supported data types in PyTorch:\n",
        "\n",
        "**Floating Point Types**\n",
        "\n",
        "  *  `torch.float32` or `torch.float`: 32-bit floating-point (default for floating point)\n",
        "  *  `torch.float64` or `torch.double`: 64-bit floating-point\n",
        "  *  `torch.float16` or `torch.half`: 16-bit floating-point (useful for mixed-precision training)\n",
        "\n",
        "**Integer Types**\n",
        "\n",
        "  *  `torch.int8`: 8-bit signed integer\n",
        "  *  `torch.uint8`: 8-bit unsigned integer\n",
        "  *  `torch.int16` or `torch.short`: 16-bit signed integer\n",
        "  *  `torch.int32` or `torch.int`: 32-bit signed integer (default for integers)\n",
        "  *  `torch.int64` or `torch.long`: 64-bit signed integer (often used as the default integer type)\n",
        "\n",
        "**Boolean Type**\n",
        "\n",
        "  *  `torch.bool`: Boolean type (stores True or False values)\n",
        "\n",
        "**Complex Number Types**\n",
        "\n",
        "  * `torch.complex64`: 64-bit complex number (real and imaginary parts as float32)\n",
        "  * `torch.complex128`: 128-bit complex number (real and imaginary parts as float64)\n",
        "\n",
        "**Quantized Types** (used in quantization for model optimization)\n",
        "\n",
        "  *  `torch.qint8`: 8-bit quantized integer\n",
        "  *  `torch.quint8`: 8-bit unsigned quantized integer\n",
        "  * `torch.qint32`: 32-bit quantized integer\n",
        "\n",
        "Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "lhZg_Du5NPXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7455240-5888-4951-912c-024a7a9d01f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.int64, torch.float32, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "x = torch.tensor([1, 2])  # Let torch choose the datatype\n",
        "y = torch.tensor([1.0, 2.0])  # Let torch choose the datatype\n",
        "z = torch.tensor([1, 2], dtype=torch.int64)  # Force a particular datatype\n",
        "\n",
        "x.dtype, y.dtype, z.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5vto3h6NPXY"
      },
      "source": [
        "### Changing and adding dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x27N2FAWNPXY"
      },
      "source": [
        "You can **transpose** dimensions within an array using arbitrary axis permutations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fXnBiHqNPXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f44349b-d2bc-4864-9da2-9bfde886d128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3, 5) dtype=torch.float32:\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "\n",
            "shape=(5, 3) dtype=torch.float32:\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "shape=(5, 3) dtype=torch.float32:\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones((3, 5))\n",
        "print_arr(a)\n",
        "print_arr(a.transpose(0, 1))\n",
        "print_arr(a.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBEdHpDcNPXa"
      },
      "source": [
        "Use `permute()` to transpose multiple dimensions simultaneously, [documentation about premuting](https://pytorch.org/docs/stable/generated/torch.permute.html#torch.permute)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAkb5CkuNPXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06fae1af-9931-405d-d77b-e39bb1c07b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 4, 6) dtype=torch.float32:\n",
            "tensor([[[  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.]],\n",
            "\n",
            "        [[  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1., 777.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.]]])\n",
            "\n",
            "shape=(4, 2, 6) dtype=torch.float32:\n",
            "tensor([[[  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.]],\n",
            "\n",
            "        [[  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.]],\n",
            "\n",
            "        [[  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1., 777.,   1.,   1.]],\n",
            "\n",
            "        [[  1.,   1.,   1.,   1.,   1.,   1.],\n",
            "         [  1.,   1.,   1.,   1.,   1.,   1.]]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones((2, 4, 6))\n",
        "a[1,2,3] = 777\n",
        "\n",
        "print_arr(a)\n",
        "\n",
        "print_arr(a.permute(1,0,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGqjdUp1NPXa"
      },
      "source": [
        "Note that an element `[x,y,z]` moves to position `[y,x,z]` after a transpose with this permutation (1,0,2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSXDY8_XNPXa"
      },
      "source": [
        "Another important feature is **reshaping** an array into different dimensions. More about [reshaping](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXDe4E8UNPXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a676a6cd-5688-4bcf-ac54-68afc6180cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3, 6) dtype=torch.int64:\n",
            "tensor([[29, 98,  4, 72, 44, 47],\n",
            "        [30, 46, 41, 11, 22, 60],\n",
            "        [40, 56, 87, 85, 91,  7]])\n",
            "\n",
            "shape=(2, 9) dtype=torch.int64:\n",
            "tensor([[29, 98,  4, 72, 44, 47, 30, 46, 41],\n",
            "        [11, 22, 60, 40, 56, 87, 85, 91,  7]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = torch.randint(0, 100, (3, 6))\n",
        "print_arr(a)\n",
        "\n",
        "# Reshape `a` from its original shape (3, 6) to a new shape (2, 9)\n",
        "# This keeps the total number of elements the same (3*6 = 2*9 = 18)\n",
        "reshaped_a = torch.reshape(a, (2, 9))\n",
        "print_arr(reshaped_a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnXPgUfxNPXa"
      },
      "source": [
        "When reshaping, we need to make sure to preserve the same number of elements.\n",
        "Use `-1` in one of the dimensions to tell numpy to \"figure it out\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkcg5sj9NPXa"
      },
      "source": [
        "You can also combine multiple arrays with **concatenation** along an arbitrary axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkPfDXE8NPXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88802a5-1180-4883-bd9f-a042e0a00b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 2) dtype=torch.int64:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\n",
            "shape=(1, 2) dtype=torch.int64:\n",
            "tensor([[5, 6]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define tensor `a` with shape (2, 2)\n",
        "# Define tensor `b` with shape (1, 2)\n",
        "\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "b = torch.tensor([[5, 6]])\n",
        "\n",
        "print_arr(a)\n",
        "print_arr(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZOSEIPjNPXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15dd46ee-aecd-4c5c-abc1-81f11de73777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(3, 2) dtype=torch.int64:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Concatenate `a` and `b` along dimension 0 (row-wise)\n",
        "# This stacks `b` as an additional row below `a`, resulting in a tensor with shape (3, 2)\n",
        "print_arr(torch.cat((a, b), dim=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFjyRqmfNPXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96867be5-2e33-4b44-9fb6-8b97d705a813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(2, 3) dtype=torch.int64:\n",
            "tensor([[1, 2, 5],\n",
            "        [3, 4, 6]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Transpose `b` to shape (2, 1) so it can be concatenated with `a` along dimension 1 (column-wise)\n",
        "# Concatenate `a` and the transposed `b` along dimension 1, resulting in a tensor with shape (2, 3)\n",
        "print_arr(torch.cat((a, b.T), dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQK7NlQfNPXb"
      },
      "source": [
        "### Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-NdlqeINPXc"
      },
      "source": [
        "Broadcasting is a powerful mechanism that allows pytorch to work with arrays of **different shapes** when performing arithmetic operations. This mechanism also exists in numpy with the same semantics.\n",
        "\n",
        "Frequently we have a smaller array and a larger array, and we want to use the smaller array multiple times to perform some operation on the larger array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDvbIg75NPXc"
      },
      "source": [
        "For example, suppose that we want to add a constant vector to each row of a matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "68P6Z4sNNPXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2751018-efff-4a85-c5a4-50ea5586ff78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=(4, 3) dtype=torch.int64:\n",
            "x=\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "shape=(3,) dtype=torch.int64:\n",
            "\n",
            "v=tensor([1, 0, 1])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We will add the vector v to each row of the matrix x,\n",
        "# storing the result in the matrix y\n",
        "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = torch.tensor([1, 0, 1])\n",
        "\n",
        "print_arr(x,'x=\\n')\n",
        "print_arr(v, '\\nv=')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDbcH4dRNPXd"
      },
      "source": [
        "**Nave approach**: Use a loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0l2R28LANPXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d8c583f-b527-4391-ae79-6e04c80dbf6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  2,  4],\n",
              "        [ 5,  5,  7],\n",
              "        [ 8,  8, 10],\n",
              "        [11, 11, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "y = torch.empty_like(x)   # Create an empty matrix with the same shape as x\n",
        "\n",
        "# Add the vector v to each row of the matrix x with an explicit loop\n",
        "for i in range(4):\n",
        "    y[i, :] = x[i, :] + v\n",
        "\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Efk7cdkNPXe"
      },
      "source": [
        "This works; however computing explicit loops in Python is **slow**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaUaeNcGNPXe"
      },
      "source": [
        "**Nave approach 2**: adding the vector v to each row of the matrix `x` is equivalent to forming a matrix `vv` by stacking multiple copies of `v` vertically, then performing elementwise summation of `x` and `vv`.\n",
        "\n",
        "We could implement this approach like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Hq-dWY3CNPXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567812b6-128a-4a5c-cc80-116d04254c77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 1],\n",
              "        [1, 0, 1],\n",
              "        [1, 0, 1],\n",
              "        [1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "vv = torch.tile(v, (4, 1))  # Stack 4 copies of v on top of each other\n",
        "vv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "voc0TYDoNPXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e887ba-0d71-46f2-8443-936cd61d167b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  2,  4],\n",
              "        [ 5,  5,  7],\n",
              "        [ 8,  8, 10],\n",
              "        [11, 11, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "y = x + vv  # Add x and vv elementwise\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTNzFcJ5NPXf"
      },
      "source": [
        "Nice, but:\n",
        "- A new array was allocated and memory was copied.\n",
        "- We had to explicitly define how many times to replicate v."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sV5EOyrNPXf"
      },
      "source": [
        "**Broadcasting** allows us to perform this computation without actually creating multiple copies of v. Consider this version, using broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "HxTd1bVwzqjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5d542b-21c3-4bb6-9c4a-e2200d872e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3],\n",
              "        [ 4,  5,  6],\n",
              "        [ 7,  8,  9],\n",
              "        [10, 11, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "id": "KjdtgqwEzwRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c41651-ee84-463e-f2d0-6dd1395a6161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "g0RV8U-JNPXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97806ab-6fbf-4a11-f072-6be042bee818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes: x=(4, 3), v=(3,)\n",
            "\n",
            "shape=(4, 3) dtype=torch.int64:\n",
            "tensor([[ 2,  2,  4],\n",
            "        [ 5,  5,  7],\n",
            "        [ 8,  8, 10],\n",
            "        [11, 11, 13]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = torch.tensor([1, 0, 1])\n",
        "\n",
        "# Add v to each row of x using broadcasting\n",
        "y = x + v\n",
        "\n",
        "print(f'shapes: x={tuple(x.shape)}, v={tuple(v.shape)}\\n')\n",
        "print_arr(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ARMpVJNNPXf"
      },
      "source": [
        "The line `y = x + v` works even though `x` has shape `(4, 3)` and `v` has shape `(3,)` due to broadcasting; this line works **as if** v actually had shape `(4, 3)`, where each row was a copy of `v`, and the sum was performed elementwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzhuB0H5NPXf"
      },
      "source": [
        "Broadcasting two tensors together follows these rules:\n",
        "\n",
        "1. All input tensors with rank smaller than the input tensor of largest rank, have **1s prepended to their shapes**.\n",
        "  \n",
        "  * Example:\n",
        "\n",
        "    Tensor `x` has shape `(4, 3)`.\n",
        "    Tensor `v` has shape `(3)` (1D).\n",
        "\n",
        "    To align their ranks, Tensor `v`'s shape becomes `(1, 3)` by prepending a dimension of size `1`, so now both tensors have two dimensions.\n",
        "\n",
        "2. The shape of the output tensor is determined by taking the maximum size in each dimension across all input tensors.\n",
        "\n",
        "  * Example:\n",
        "\n",
        "    After aligning ranks, where `x` has shape `(4, 3)` and `v` has shape `(1, 3)`.\n",
        "    The output shape will be `(4, 3)`, as this is the largest dimension size in each corresponding position.\n",
        "\n",
        "3. For broadcasting to work, each dimension of the input tensors must either: **Match the size of the output shape in that dimension**, or **Have a size of 1, which allows it to be \"stretched\" to match the output size**.\n",
        "\n",
        "  * Example:\n",
        "\n",
        "    For `x` with shape `(4, 3)` and `v` with shape `(1, 3)`, both can broadcast to an output shape of `(4, 3)`.\n",
        "    The first dimension of `v` is `1`, so it stretches to `4` to match `x`.\n",
        "\n",
        "4. If a tensor has a dimension size of 1, it means there is only one value along that dimension. Broadcasting will automatically repeat this value across the expanded dimension to match the size of the other tensors.\n",
        "\n",
        " * Example:\n",
        "\n",
        "    For `v` with shape `(1, 3)`, the single row (size 1) will be repeated `4` times to match the `(4, 3)` shape of `x`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDIAl5FNNPXg"
      },
      "source": [
        "Our example in short:\n",
        "- `x` has shape `(4,3)`\n",
        "- `v` has shape `(3,)`.\n",
        "\n",
        "Following the Broadcasting logic, we can say the following is equivalent to what happened:\n",
        "1. `v` has less dims than `x` so a dimension of `1` is **prepended** -> `v` is now `(1, 3)`.\n",
        "1. Output shape will be `(max(1,4), max(3,3)) = (4,3)`.\n",
        "1. Dim 1 of `v` matches exactly (3): so it's clear which data to use.\n",
        "1. Dim 0 is exactly 1 for `v` and 4 for `x`: we can use the first data entry (row 0) of `v` for each time any of its rows is accessed. This is effectively like converting `v` from `(1,3)` to `(4,3)` by replicating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4hBnBZDNPXg"
      },
      "source": [
        "Broadcasting is incredibly useful and necessary for writing **vectorized** code,\n",
        "i.e. code that avoids explicit python loops which are very slow.\n",
        "Instead, this approach leveraged the underlying C implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y380mfhLNPXg"
      },
      "source": [
        "#### Another Example: Calculating an outer-product with elementsize product and broadcasting:\n",
        "\n",
        "(go over alone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true,
        "id": "O54SMHSONPXg"
      },
      "outputs": [],
      "source": [
        "# Compute outer product of the vectors\n",
        "v = torch.tensor([1,2,3])  # v has shape (3,)\n",
        "w = torch.tensor([4,5])    # w has shape (2,)\n",
        "print_arr(v)\n",
        "print_arr(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "CX8R2kQ-NPXh"
      },
      "source": [
        "To compute an outer product, we first reshape `v` to be a column\n",
        "vector of shape `(3, 1)`; we can then broadcast it against `w` to yield\n",
        "an output of shape `(3, 2)`, which is the outer product of `v` and `w`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "cWlbPerVNPXh"
      },
      "outputs": [],
      "source": [
        "# (3,1) * (2,) -> (3,1) * (1, 2) -> (3, 2) * (3, 2)\n",
        "torch.reshape(v, (3, 1)) * w # note that * is elementwise!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.reshape(v, (3, 1))"
      ],
      "metadata": {
        "id": "pGbUjqpsfyI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "que47Qy7NPXh"
      },
      "outputs": [],
      "source": [
        "# Multiply a matrix by a constant:\n",
        "x = torch.ones((2,3))\n",
        "\n",
        "# x has shape (2, 3). Numpy treats scalars as arrays of shape ();\n",
        "# these can be broadcast together to shape (2, 3).\n",
        "\n",
        "# (2,3) * () -> (2,3) * (1,1) -> (2,3) * (2,3)\n",
        "x * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq4cSk94NPXi"
      },
      "source": [
        "Broadcasting typically makes your code more concise and faster, so you should strive to use it where possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.014666,
          "end_time": "2023-10-11T15:26:01.138401",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.123735",
          "status": "completed"
        },
        "tags": [],
        "id": "7b1fdd9c"
      },
      "source": [
        "### Dynamic Computation Graph and Backpropagation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define.\n",
        "We will mainly use PyTorch for implementing neural networks, and they are just fancy functions.\n",
        "If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n",
        "\n",
        "If our neural network would output a single scalar value, we would talk about taking the **derivative**, but you will see that quite often we will have **multiple** output variables (\"values\"); in that case we talk about **gradients**.\n",
        "It's a more general term.\n",
        "\n",
        "Given an input $\\mathbf{x}$, we define our function by **manipulating** that input, usually by matrix-multiplications with weight matrices and additions with so-called bias vectors.\n",
        "As we manipulate our input, we are automatically creating a **computational graph**.\n",
        "This graph shows how to arrive at our output from our input.\n",
        "PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us.\n",
        "Thus, we create a dynamic computation graph along the way.\n",
        "\n",
        "So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**.\n",
        "\n",
        "> **Why do we want gradients?**\n",
        "\n",
        "> Consider that we have defined a function, a neural net, that is supposed to compute a certain output $y$ for an input vector $\\mathbf{x}$.\n",
        "We then define an **error measure** that tells us how wrong our network is; how bad it is in predicting output $y$ from input $\\mathbf{x}$.\n",
        "Based on this error measure, we can use the gradients to **update** the weights $\\mathbf{W}$ that were responsible for the output, so that the next time we present input $\\mathbf{x}$ to our network, the output will be closer to what we want.\n",
        "\n",
        "The first thing we have to do is to specify which tensors require gradients.\n",
        "By default, when we create a tensor, it does not require gradients."
      ],
      "metadata": {
        "id": "rslK3nrSGXuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "BJzS2OU_sQqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af1f073-b19f-4f45-afbf-7eca5d7b662d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "eAzJTlq74Or5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ae704b-f6d7-4fe6-d0d2-607ff467c932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015475,
          "end_time": "2023-10-11T15:26:01.206055",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.190580",
          "status": "completed"
        },
        "tags": [],
        "id": "dbe9569e"
      },
      "source": [
        "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation).\n",
        "Alternatively, when creating a tensor, you can pass the argument\n",
        "`requires_grad=True` to most initializers we have seen above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)\n",
        "\n",
        "# alternative: set from creation e.g. x = torch.ones((3,), requires_grad=True)"
      ],
      "metadata": {
        "id": "fg6kGxqdscLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21c937c-c6d0-4958-b073-2629aa1e60a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.014826,
          "end_time": "2023-10-11T15:26:01.273716",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.258890",
          "status": "completed"
        },
        "tags": [],
        "id": "4859b856"
      },
      "source": [
        "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$.\n",
        "For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$.\n",
        "For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True)  # Only float tensors can have gradients\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "FIW2FAl_sgcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75302a9-79c2-448e-df54-77533f3459e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0., 1., 2.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = x + 2\n",
        "b = a**2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)\n",
        "\n",
        "# y = (((x+2)**2)+3).mean()"
      ],
      "metadata": {
        "id": "zFcCPWkQ56wR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e14ee0-cb23-413b-a3bb-3b25111dfa7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015001,
          "end_time": "2023-10-11T15:26:01.342813",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.327812",
          "status": "completed"
        },
        "tags": [],
        "id": "cd57fffd"
      },
      "source": [
        "Now let's build the computation graph step by step.\n",
        "You can combine multiple operations in a single line, but we will\n",
        "separate them here to get a better understanding of how each operation\n",
        "is added to the computation graph."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = x + 2\n",
        "b = a**2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "aLJCpqbNsizF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b09ede2-fb8d-4dc0-d119-aebefbff1bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015298,
          "end_time": "2023-10-11T15:26:01.413466",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.398168",
          "status": "completed"
        },
        "tags": [],
        "id": "6e931011"
      },
      "source": [
        "Using the statements above, we have created a computation graph that looks similar to the figure below:\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/Lightning-AI/lightning-tutorials/raw/main/course_UvA-DL/01-introduction-to-pytorch/pytorch_computation_graph.svg\" width=\"200px\"></center>\n",
        "\n",
        "We calculate $a$ based on the inputs $x$ and the constant $2$, $b$ is $a$ squared, and so on.\n",
        "The visualization is an abstraction of the dependencies between inputs and outputs of the operations we have applied.\n",
        "Each node of the computation graph has automatically defined a function for calculating the gradients with respect to its inputs, `grad_fn`.\n",
        "You can see this when we printed the output tensor $y$.\n",
        "This is why the computation graph is usually visualized in the reverse direction (arrows point from the result to the inputs).\n",
        "We can perform backpropagation on the computation graph by calling the\n",
        "function `backward()` on the last output, which effectively calculates\n",
        "the gradients for each tensor that has the property\n",
        "`requires_grad=True`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "f5NQePFetJ0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "jexiCQop60PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de2016a-204d-4727-b91d-948972e441d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.01503,
          "end_time": "2023-10-11T15:26:01.574513",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.559483",
          "status": "completed"
        },
        "tags": [],
        "id": "303c8c9c"
      },
      "source": [
        "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T15:26:01.605535Z",
          "iopub.status.busy": "2023-10-11T15:26:01.605365Z",
          "iopub.status.idle": "2023-10-11T15:26:01.611266Z",
          "shell.execute_reply": "2023-10-11T15:26:01.610373Z"
        },
        "papermill": {
          "duration": 0.022884,
          "end_time": "2023-10-11T15:26:01.612523",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.589639",
          "status": "completed"
        },
        "tags": [],
        "id": "d3e89cdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03435edc-de48-4d34-bdea-b00eae356557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3333, 2.0000, 2.6667])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015571,
          "end_time": "2023-10-11T15:26:01.643358",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.627787",
          "status": "completed"
        },
        "tags": [],
        "id": "1e421f85"
      },
      "source": [
        "We can also verify these gradients by hand.\n",
        "We will calculate the gradients using the chain rule, in the same way as PyTorch did it:\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
        "\n",
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor.\n",
        "The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$.\n",
        "The previous code cell should have printed the same result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015467,
          "end_time": "2023-10-11T15:26:01.674289",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.658822",
          "status": "completed"
        },
        "tags": [],
        "id": "6943f1a8"
      },
      "source": [
        "### GPU support\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A crucial feature of PyTorch is the support of GPUs, short for Graphics Processing Unit.\n",
        "A GPU can perform many thousands of small operations in parallel, making it very well suitable for performing large matrix operations in neural networks.\n",
        "When comparing GPUs to CPUs, we can list the following main differences (credit: [Kevin Krewell, 2009](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/))\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/Lightning-AI/lightning-tutorials/raw/main/course_UvA-DL/01-introduction-to-pytorch/comparison_CPU_GPU.png\" width=\"700px\"></center>\n",
        "\n",
        "CPUs and GPUs have both different advantages and disadvantages, which is why many computers contain both components and use them for different tasks.\n",
        "In case you are not familiar with GPUs, you can read up more details in this [NVIDIA blog post](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/) or [here](https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html).\n",
        "\n",
        "GPUs can accelerate the training of your network up to a factor of $100$ which is essential for large neural networks.\n",
        "PyTorch implements a lot of functionality for supporting GPUs (mostly those of NVIDIA due to the libraries [CUDA](https://developer.nvidia.com/cuda-zone) and [cuDNN](https://developer.nvidia.com/cudnn)).\n",
        "First, let's check whether you have a GPU available:"
      ],
      "metadata": {
        "id": "kCnGvJGfGbNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T15:26:01.706783Z",
          "iopub.status.busy": "2023-10-11T15:26:01.706215Z",
          "iopub.status.idle": "2023-10-11T15:26:01.710815Z",
          "shell.execute_reply": "2023-10-11T15:26:01.710168Z"
        },
        "papermill": {
          "duration": 0.022125,
          "end_time": "2023-10-11T15:26:01.711968",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.689843",
          "status": "completed"
        },
        "tags": [],
        "id": "772045e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30570e29-98a0-4975-8099-27c3240d2852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? False\n"
          ]
        }
      ],
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015252,
          "end_time": "2023-10-11T15:26:01.742625",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.727373",
          "status": "completed"
        },
        "tags": [],
        "id": "eaea6906"
      },
      "source": [
        "If you have a GPU on your computer but the command above returns False, make sure you have the correct CUDA-version installed.\n",
        "The `dl2020` environment comes with the CUDA-toolkit 10.1, which is selected for the Lisa supercomputer.\n",
        "Please change it if necessary (CUDA 10.2 is currently common).\n",
        "On Google Colab, make sure that you have selected a GPU in your runtime setup (in the menu, check under `Runtime -> Change runtime type`).\n",
        "\n",
        "By default, all tensors you create are stored on the CPU.\n",
        "We can push a tensor to the GPU by using the function `.to(...)`, or `.cuda()`.\n",
        "However, it is often a good practice to define a `device` object in your code which points to the GPU if you have one, and otherwise to the CPU.\n",
        "Then, you can write your code with respect to this device object, and it allows you to run the same code on both a CPU-only system, and one with a GPU.\n",
        "Let's try it below.\n",
        "We can specify the device as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T15:26:01.774681Z",
          "iopub.status.busy": "2023-10-11T15:26:01.774143Z",
          "iopub.status.idle": "2023-10-11T15:26:01.779247Z",
          "shell.execute_reply": "2023-10-11T15:26:01.778315Z"
        },
        "papermill": {
          "duration": 0.022549,
          "end_time": "2023-10-11T15:26:01.780534",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.757985",
          "status": "completed"
        },
        "tags": [],
        "id": "e9027be6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455a0854-61d7-4546-a3da-0eb29eb84472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015338,
          "end_time": "2023-10-11T15:26:01.811341",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.796003",
          "status": "completed"
        },
        "tags": [],
        "id": "93cb3af0"
      },
      "source": [
        "Now let's create a tensor and push it to the device:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T15:26:01.844561Z",
          "iopub.status.busy": "2023-10-11T15:26:01.843561Z",
          "iopub.status.idle": "2023-10-11T15:26:02.089559Z",
          "shell.execute_reply": "2023-10-11T15:26:02.089056Z"
        },
        "papermill": {
          "duration": 0.263848,
          "end_time": "2023-10-11T15:26:02.090604",
          "exception": false,
          "start_time": "2023-10-11T15:26:01.826756",
          "status": "completed"
        },
        "tags": [],
        "id": "c47c2018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227ef8ac-ccec-4649-c31a-e1de563e420c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015382,
          "end_time": "2023-10-11T15:26:02.121525",
          "exception": false,
          "start_time": "2023-10-11T15:26:02.106143",
          "status": "completed"
        },
        "tags": [],
        "id": "452898ef"
      },
      "source": [
        "In case you have a GPU, you should now see the attribute `device='cuda:0'` being printed next to your tensor.\n",
        "The zero next to cuda indicates that this is the zero-th GPU device on your computer.\n",
        "PyTorch also supports multi-GPU systems, but this you will only need once you have very big networks to train (if interested, see the [PyTorch documentation](https://pytorch.org/docs/stable/distributed.html#distributed-basics)).\n",
        "We can also compare the runtime of a large matrix multiplication on the CPU with a operation on the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T15:26:02.154073Z",
          "iopub.status.busy": "2023-10-11T15:26:02.153518Z",
          "iopub.status.idle": "2023-10-11T15:26:02.683637Z",
          "shell.execute_reply": "2023-10-11T15:26:02.683136Z"
        },
        "papermill": {
          "duration": 0.547926,
          "end_time": "2023-10-11T15:26:02.684945",
          "exception": false,
          "start_time": "2023-10-11T15:26:02.137019",
          "status": "completed"
        },
        "tags": [],
        "id": "1a83efe1"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "# CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "# GPU version\n",
        "if torch.cuda.is_available():\n",
        "    x = x.to(device)\n",
        "    # CUDA is asynchronous, so we need to use different timing functions\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    start.record()\n",
        "    _ = torch.matmul(x, x)\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "    print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015697,
          "end_time": "2023-10-11T15:26:02.717519",
          "exception": false,
          "start_time": "2023-10-11T15:26:02.701822",
          "status": "completed"
        },
        "tags": [],
        "id": "74d8ced5"
      },
      "source": [
        "Depending on the size of the operation and the CPU/GPU in your system, the speedup of this operation can be >50x.\n",
        "As `matmul` operations are very common in neural networks, we can already see the great benefit of training a NN on a GPU.\n",
        "The time estimate can be relatively noisy here because we haven't run it for multiple times.\n",
        "Feel free to extend this, but it also takes longer to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C85irj9BNPXk"
      },
      "source": [
        "**Credits**\n",
        "\n",
        "Parts of this tutorial were adapted from [CS236781 Technion Tutorial 00](https://github.com/vistalab-technion/cs236781-tutorials/tree/master/t00%20-%20python%2C%20numpy%2C%20torch) which was written by [Aviv A. Rosenberg](https://avivr.net).<br>\n",
        "\n",
        "\n",
        "Some images in this tutorial were taken and/or adapted from the following sources:\n",
        "- https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry\n",
        "\n",
        "The Python section here was adapted from:\n",
        "- [CS231n Python tutorial](http://cs231n.github.io/python-numpy-tutorial/) by Justin Johnson."
      ]
    }
  ]
}